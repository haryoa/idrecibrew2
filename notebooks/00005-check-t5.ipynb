{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data4/haryoaw_workspace/projects/2021_2/mbekk/idrecibrew2\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrecibrew2.data import Seq2SeqDataFactory, Seq2SeqDataFactoryArgs\n",
    "from idrecibrew2.data.indonlg_tokenizer.tokenizer import IndoNLGTokenizer\n",
    "from idrecibrew2.model import LitSeq2SeqTransformers, LitSeq2SeqTransformersArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Wikidepia/IndoT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁saya', '▁adalah', '▁pen', 'gembala', '▁sapi', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"saya adalah pengembala sapi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_seq = Seq2SeqDataFactoryArgs(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =Seq2SeqDataFactory(args_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574f6459fa8948598c5f4eb7125471de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl = df.produce_dataloader_from_csv(\"data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0]]), 'input_ids': tensor([[16689,  2322,   858,  1750,     1],\n",
       "        [16689, 25237,  3434,     1,     0]]), 'labels': tensor([[   86,   749, 16689,    11,     4, 16296,  5555,   858,   228,    11,\n",
       "            75,   721, 14856,    11,     5,    11,     2,  7846,    11,    39,\n",
       "            11,     2,   237,   980,   686,  4439,  1074,    11,     4,  2293,\n",
       "         11961,    11,     5,    11,     2,   173,   980,   686,  4439,   950,\n",
       "            11,     4,  2293, 11961,    11,     5,    11,     2,    78, 11638,\n",
       "          3801,    11,     7,  5448,  5105,    11,     4,  7298,    19,   200,\n",
       "           165,   158,   223,   190,    11,     5,    11,     2,    86,   165,\n",
       "           158,   223,  3191,    11,     2,    78,   165,  8029,  3434,    11,\n",
       "             2,   279,   165,  8029, 14340,  4066,    11,     2,   285,   749,\n",
       "         25237,  1074,    11,     4, 28255,    11,     8,  1535,  3576,  1655,\n",
       "           359,    11,     5,    11,     2,  1218,   485,   282,   190,    11,\n",
       "             2,    11,     1],\n",
       "        [   78,  3442, 16689,    11,     4, 16296,  2107,  1069,    11,     5,\n",
       "            11,     2,   493, 20304,    23,  6683,  7846, 21572,    11,     4,\n",
       "          1535,  9572, 18117,   437, 21572,    11,     5,    11,     2,   324,\n",
       "           980,   686,  4439,   950,    11,     4, 27550,    11,     5,    11,\n",
       "             2,   324, 25237,  1074,    11,     4,  2379,  6405,  1845,  7421,\n",
       "            11,     8, 27550,    11,     5,    11,     2,   493, 20304,    23,\n",
       "          1229,  4439,    11,     2,   493, 20734,   712,  3434,    11,     2,\n",
       "           200, 23551,  1491,  1341,  7307,    11,     4,    21,  6132,  2676,\n",
       "          4439,   950,    11,     5,    11,     2,    11,     1,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model_args = LitSeq2SeqTransformersArgs(\n",
    "    vocab_size=tokenizer.vocab_size, model_type=\"Wikidepia/IndoT5-base\"\n",
    ")\n",
    "lit_model = LitSeq2SeqTransformers(config=lit_model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.generate(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([30827])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12281, 30827, 11, 1], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" @@ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_model = LitSeq2SeqTransformers.load_from_checkpoint(\"outputs/indo-t5/model-epoch=27-val_loss=1.287.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_dl = tokenizer(\"sop ayam\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer.decode(recipe_model.model.generate(input_to_dl['input_ids'], num_beams=1, max_length=400, top_k=1, repetition_penalty=1.1, do_sample=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> 1 / 2 kg ayam @@ 3 siung bawang putih @@ 4 siung bawang merah @@ 1 ruas jahe @@ 1 sdt ketumbar bubuk @@ secukupnya garam @@ secukupnya gula pasir @@ secukupnya air @@ minyak untuk menumis @@ </s>'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed for T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [\"train\", \"dev\", \"test\"]:\n",
    "    df = pd.read_csv(f\"data/processed/{data}.csv\")\n",
    "    df['tgt'] = df.tgt.str.replace(\"||\", \"@@\", regex=False)\n",
    "    df.to_csv(f\"data/processed/{data}_t5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sylveon",
   "language": "python",
   "name": "sylveon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
