{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\SelfProject\\IndoRecipe2\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrecibrew2.data.indonlg_tokenizer.tokenizer import IndoNLGTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = IndoNLGTokenizer.from_pretrained(\"indobenchmark/indobart-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', '<0x54>', 'esting', '▁yah']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Testing yah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_source = 'src'\n",
    "column_target = 'tgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 256\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples['src']\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"tgt\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(example_data, idx):\n",
    "    tokenized_input = {}\n",
    "    tokenized_input.update({key: dict(tokenizer(example_data[key]))['input_ids'] for key in [column_source, column_target]})\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.82ba/s]\n"
     ]
    }
   ],
   "source": [
    "hasil = data.map(preprocess_function, with_indices=False, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'basic_ingredient', 'input_ids', 'labels', 'no', 'src', 'tgt'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = hasil.remove_columns(['no', 'basic_ingredient', 'src', 'tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForSeq2Seq(tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coba = DataLoader(hasil, 4, collate_fn = collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'input_ids': tensor([[    0, 25270, 12338,  3353,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    0,   486,  5957,  2681,   306, 39974, 16576,   299, 33716, 12338,\n",
       "          7727,   327,   244,   163,   139,   178,   244,   163,   139,   173,\n",
       "         39965,     2],\n",
       "        [    0,  3569,  3793, 12338, 19340,  4046, 24919,     2,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    0,   771,   459, 12338,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]]), 'labels': tensor([[    0,   406,  4883, 12338,  1366,  1935,   483,  3230,  3103,   909,\n",
       "          1782, 13235, 25075,   327,  2080,  3034,   470,   632,  1364,   329,\n",
       "          3103,   814,  9744,  4480,  2279,  3103,   628,  9744,  4480,  2074,\n",
       "          3103,   322,  3138,   502,   418,  7302,  5935, 39964,  3103,  1437,\n",
       "         27256,  5654,  1690, 27256,  2395,  3103,  6229,  3103,  4195,  4759,\n",
       "          3103,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [    0,  1186,   443,  3103,  1378,   292,   483,  3138, 33716,   279,\n",
       "         18738,   502,   499,  3103,   406,   508,   322,  4883, 12338,   279,\n",
       "         18738, 23815,  3103,   406,  1782, 13235,  2279,   279, 18738,   502,\n",
       "           499,  3103,   377,  1782, 13235, 25075,   279, 18738,   502,   499,\n",
       "          3103, 12956,  2582,  7295,   327,   505,   314,  1437,   329,  3103,\n",
       "          3103,  5797,   443,  3103,   533, 35653,  4480,  2074,   279, 36215,\n",
       "          3103,   647, 35653,  4480,  2279,   279, 36215,  3103,   533,  8101,\n",
       "          7727,  3793,  3103,   406,   508,   322,  8101, 13238, 20650,  3103,\n",
       "         12956,  6229,   279,  4195,   279, 19413,  8722,  3103,     2],\n",
       "        [    0,   406,  4883, 12338,  3103, 19340,   327,  5147,   571,  1804,\n",
       "           329,  3103,   814,  4046, 24919,  3103,   533, 35653,  4480,  2279,\n",
       "          3103,   533, 35653,  4480,  2074,  3103,   406,  4480, 32742,  3103,\n",
       "         13235,  2279,   327,  1143,  7311,   329,  3103, 13235, 25075,   327,\n",
       "           528,   277, 22952,  2134,   795,   363,  9773,   329,  3103, 13238,\n",
       "         11074,  3103, 13238, 12016,  3103,  6229,   309, 31175,  3103,     2,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [    0,   406,  4883, 12338,  3103, 12956, 33716,  3103,   533,  5620,\n",
       "         11249,  3563,   735,  3103,   322, 35653,  4480,  2074,  3103,   406,\n",
       "          8101,  7727, 20650,  3103,   647,  8101,  7727,  3793,  3103, 12956,\n",
       "          4195,   279,  6229,   279, 31175,  3103,     2,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(coba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62852\\miniconda3\\envs\\idrecibrew2\\lib\\importlib\\__init__.py:169: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95f30b99fefbe504a71f06ce13ca8c06569550641ec5e366cd8ec530130f11ba"
  },
  "kernelspec": {
   "display_name": "Sylveon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
