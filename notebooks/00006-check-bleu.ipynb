{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrecibrew2.data import Seq2SeqDataFactory, Seq2SeqDataFactoryArgs\n",
    "from idrecibrew2.data.indonlg_tokenizer.tokenizer import IndoNLGTokenizer\n",
    "from idrecibrew2.model import LitSeq2SeqTransformers, LitSeq2SeqTransformersArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrecibrew2.eval.training_eval import Seq2SeqTrainingEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndoBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = IndoNLGTokenizer.from_pretrained(\"indobenchmark/indobart-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_df = Seq2SeqDataFactoryArgs(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Seq2SeqDataFactory(args_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b541b63808b5493c809df90babceea2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = df.produce_dataloader_from_csv(\"data/processed/test.csv\", batch_size=64, n_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitSeq2SeqTransformers.load_from_checkpoint(\"outputs/indobert-v2/model-epoch=24-val_loss=1.731-val_bleu=26.443.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = lit_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for batch in tqdm(test_dl):\n",
    "    argmax = lit_model.model.generate(\n",
    "        input_ids=batch[\"input_ids\"].to(device),\n",
    "        max_length=300,\n",
    "        num_return_sequences=1,\n",
    "        num_beams=1,\n",
    "        num_beam_groups=1,\n",
    "    )\n",
    "    outputs.append({\"preds\": argmax, \"tgts\": batch.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Seq2SeqTrainingEval(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_test = evaluator.compute_eval(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.03383393952166"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Wikidepia/IndoT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_df = Seq2SeqDataFactoryArgs(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Seq2SeqDataFactory(args_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"data/processed/test_t5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>basic_ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2139</td>\n",
       "      <td>ikan patin asam manis</td>\n",
       "      <td>resep: 1 ekor ikan patin ,  potong dadu ,  buang tulangnya @@ 1 / 4 kg tepung terigu @@ garam @@ lada bubuk @@ bumbu saus  :  @@ 5 sachet saos cabai @@ 10 sachet saos tomat @@ 1 butir bawang bombai @@ 1 / 4 gelas air @@</td>\n",
       "      <td>ikan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>3532</td>\n",
       "      <td>tim ikan blanak</td>\n",
       "      <td>resep: 5 ekor ikan blanak @@ jeruk nipis @@ 2 sihung bawang putih @@ 1 ruas jahe memarkan @@ 1 ruas kayu manis @@ 2 btg bawang prei @@ garam @@ 500 ml air @@</td>\n",
       "      <td>ikan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no                    src  \\\n",
       "150  2139  ikan patin asam manis   \n",
       "973  3532  tim ikan blanak         \n",
       "\n",
       "                                                                                                                                                                                                                              tgt  \\\n",
       "150  resep: 1 ekor ikan patin ,  potong dadu ,  buang tulangnya @@ 1 / 4 kg tepung terigu @@ garam @@ lada bubuk @@ bumbu saus  :  @@ 5 sachet saos cabai @@ 10 sachet saos tomat @@ 1 butir bawang bombai @@ 1 / 4 gelas air @@    \n",
       "973  resep: 5 ekor ikan blanak @@ jeruk nipis @@ 2 sihung bawang putih @@ 1 ruas jahe memarkan @@ 1 ruas kayu manis @@ 2 btg bawang prei @@ garam @@ 500 ml air @@                                                                  \n",
       "\n",
       "    basic_ingredient  \n",
       "150  ikan             \n",
       "973  ikan             "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30b58c15ee74f4ca24d54a7b368d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = df.produce_dataloader_from_csv(\"data/processed/test_t5.csv\", batch_size=128, n_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitSeq2SeqTransformers.load_from_checkpoint(\"outputs/indo-t5-2/model-epoch=19-val_loss=1.182.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = lit_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = lit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [09:48<00:00, 58.90s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = []\n",
    "    for batch in tqdm(test_dl):\n",
    "        argmax = lit_model.model.generate(\n",
    "            input_ids=batch[\"input_ids\"].to(device),\n",
    "            max_length=500,\n",
    "            num_return_sequences=1,\n",
    "            num_beams=1,\n",
    "            num_beam_groups=1,\n",
    "        )\n",
    "        outputs.append({\"preds\": argmax, \"tgts\": batch.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabana = tokenizer(\"tempe pedas teri\", return_tensors=\"pt\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = lit_model.model.generate(\n",
    "            input_ids=sabana,\n",
    "            max_length=300,\n",
    "            num_return_sequences=1,\n",
    "            num_beams=1,\n",
    "            num_beam_groups=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_remove_resep(x):\n",
    "    decoded = tokenizer.decode(x, skip_special_tokens=True)\n",
    "    decoded = decoded.replace(\"resep: \", \"\")\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Seq2SeqTrainingEval(tokenizer)\n",
    "bleu_test = evaluator.compute_eval(outputs, special_func=decode_remove_resep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.72685033429128"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data.\n",
    "Append \">>>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.src = df_test.src + \" >>> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"data/processed/test_gpt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict it!\n",
    "\n",
    "GPT input: \"Food title >>>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = IndoNLGTokenizer.from_pretrained(\"indobenchmark/indogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_df = Seq2SeqDataFactoryArgs(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Seq2SeqDataFactory(args_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafb76b7c7064889be0f500f6f050e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = df.produce_dataloader_from_csv(\"data/processed/test_gpt.csv\", batch_size=64, n_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitSeq2SeqTransformers.load_from_checkpoint(\"outputs/indogpt/model-epoch=06-val_loss=1.861-val_bleu=0.000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = lit_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  5%|â–Œ         | 1/20 [00:03<01:13,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|â–ˆ         | 2/20 [00:07<01:07,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:11<01:02,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [00:14<00:58,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:18<00:54,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:22<00:50,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:25<00:47,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:29<00:43,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:32<00:39,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:36<00:36,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:40<00:32,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:43<00:29,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:47<00:25,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:51<00:21,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:54<00:18,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:58<00:14,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [01:02<00:10,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [01:05<00:07,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:09<00:03,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:12<00:00,  3.65s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for batch in tqdm(test_dl):\n",
    "    argmax = lit_model.model.generate(\n",
    "        input_ids=batch[\"input_ids\"].to(device),\n",
    "        max_length=300,\n",
    "        num_return_sequences=1,\n",
    "        num_beams=1,\n",
    "        num_beam_groups=1,\n",
    "    )\n",
    "    outputs.append({\"preds\": argmax, \"tgts\": batch.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>basic_ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12913</td>\n",
       "      <td>sambel tempe kering &gt;&gt;&gt;</td>\n",
       "      <td>1 papan tempe  yg ukuran 20 cm || 8 buah cabe ...</td>\n",
       "      <td>tempe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13472</td>\n",
       "      <td>oily oseng/tumis buncis tempe kecap (ðŸ‡®ðŸ‡©) &gt;&gt;&gt;</td>\n",
       "      <td>bahan :  || 15 - 20 batang buncis ,  iris sero...</td>\n",
       "      <td>tempe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12167</td>\n",
       "      <td>asam manis tempe sosis telur puyuh &gt;&gt;&gt;</td>\n",
       "      <td>1 papan tempe || sosis  ( merk apa aja )  || 1...</td>\n",
       "      <td>tempe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13076</td>\n",
       "      <td>oreg tempe &gt;&gt;&gt;</td>\n",
       "      <td>1 papan tempe || secukupnya buncis || 3 biji c...</td>\n",
       "      <td>tempe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3224</td>\n",
       "      <td>ikan bandeng presto salted egg (telur asin) &gt;&gt;&gt;</td>\n",
       "      <td>2 buah bandeng presto || 3 butir telur asin ||...</td>\n",
       "      <td>ikan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>5827</td>\n",
       "      <td>lapis daging sapi &gt;&gt;&gt;</td>\n",
       "      <td>750 daging sapi  ( khas dalam )  || 3 lembar d...</td>\n",
       "      <td>sapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2448</td>\n",
       "      <td>pesmol ikan nila &gt;&gt;&gt;</td>\n",
       "      <td>2 ekor ikan nila || 1 buah jeruk nipis || secu...</td>\n",
       "      <td>ikan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>11007</td>\n",
       "      <td>cloud tuna &amp; egg #ketofriendly #ketopad_cp_sav...</td>\n",
       "      <td>3 butir telur ayam ,  pisahkan putih dan kunin...</td>\n",
       "      <td>telur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>8064</td>\n",
       "      <td>pepes tahu &gt;&gt;&gt;</td>\n",
       "      <td>3 biji tahu putih || 2 batang daun bawang + sl...</td>\n",
       "      <td>tahu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>3494</td>\n",
       "      <td>tenggiri bumbu bali &gt;&gt;&gt;</td>\n",
       "      <td>4 ekor ikan tenggiri || 1 buah jeruk nipis || ...</td>\n",
       "      <td>ikan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         no                                                src  \\\n",
       "0     12913                           sambel tempe kering >>>    \n",
       "1     13472      oily oseng/tumis buncis tempe kecap (ðŸ‡®ðŸ‡©) >>>    \n",
       "2     12167            asam manis tempe sosis telur puyuh >>>    \n",
       "3     13076                                    oreg tempe >>>    \n",
       "4      3224   ikan bandeng presto salted egg (telur asin) >>>    \n",
       "...     ...                                                ...   \n",
       "1275   5827                             lapis daging sapi >>>    \n",
       "1276   2448                              pesmol ikan nila >>>    \n",
       "1277  11007  cloud tuna & egg #ketofriendly #ketopad_cp_sav...   \n",
       "1278   8064                                    pepes tahu >>>    \n",
       "1279   3494                           tenggiri bumbu bali >>>    \n",
       "\n",
       "                                                    tgt basic_ingredient  \n",
       "0     1 papan tempe  yg ukuran 20 cm || 8 buah cabe ...            tempe  \n",
       "1     bahan :  || 15 - 20 batang buncis ,  iris sero...            tempe  \n",
       "2     1 papan tempe || sosis  ( merk apa aja )  || 1...            tempe  \n",
       "3     1 papan tempe || secukupnya buncis || 3 biji c...            tempe  \n",
       "4     2 buah bandeng presto || 3 butir telur asin ||...             ikan  \n",
       "...                                                 ...              ...  \n",
       "1275  750 daging sapi  ( khas dalam )  || 3 lembar d...             sapi  \n",
       "1276  2 ekor ikan nila || 1 buah jeruk nipis || secu...             ikan  \n",
       "1277  3 butir telur ayam ,  pisahkan putih dan kunin...            telur  \n",
       "1278  3 biji tahu putih || 2 batang daun bawang + sl...             tahu  \n",
       "1279  4 ekor ikan tenggiri || 1 buah jeruk nipis || ...             ikan  \n",
       "\n",
       "[1280 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lele taworcis(tahu,wortel,buncis) kuah segar >>> || 1 / 2 kg lele || 1 / 2 kg tahu || 1 / 2 kg kacang tanah || bumbu halus : || 5 siung bawang putih || 5 siung bawang merah || 1 / 2 sdt ketumbar || 1 / 2 sdt merica || 1 / 2 sdt garam || 1 / 2 sdt gula || 1 / 2 sdt penyedap rasa || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt jahe bubuk || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt garam || 1 / 2 sdtutkan ||'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0]['preds'][16], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_gpt(x):\n",
    "    decoded = tokenizer.decode(x, skip_special_tokens=True)\n",
    "    decoded_split = decoded.split(\" >>> \")\n",
    "    if len(decoded_split) == 1:\n",
    "        return decoded\n",
    "    else:  # for non-preds\n",
    "        return ' '.join(decoded_split[1:])\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|| 1 / 2 kg lele || 1 / 2 kg tahu || 1 / 2 kg kacang tanah || bumbu halus : || 5 siung bawang putih || 5 siung bawang merah || 1 / 2 sdt ketumbar || 1 / 2 sdt merica || 1 / 2 sdt garam || 1 / 2 sdt gula || 1 / 2 sdt penyedap rasa || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt jahe bubuk || 1 / 2 sdt kunyit bubuk || 1 / 2 sdt garam || 1 / 2 sdtutkan ||'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_gpt(outputs[0]['preds'][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Seq2SeqTrainingEval(tokenizer)\n",
    "bleu_test = evaluator.compute_eval(outputs, special_func=decode_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.981578042780926"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sylveon",
   "language": "python",
   "name": "sylveon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
